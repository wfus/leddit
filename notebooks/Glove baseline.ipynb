{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glove Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T19:15:10.805262Z",
     "start_time": "2020-03-14T19:15:09.049135Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import re\n",
    "sys.path.append('.')\n",
    "sys.path.append('..')\n",
    "\n",
    "from subreddit_frequency import load_dataframe_from_jsonl\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "sns.set('paper')\n",
    "\n",
    "from ipywidgets import interact\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as torch_data\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T19:15:31.297331Z",
     "start_time": "2020-03-14T19:15:31.294101Z"
    }
   },
   "outputs": [],
   "source": [
    "train_path = Path.cwd().parent / \"aita\" / \"aita-train.pkl\"\n",
    "test_path = Path.cwd().parent / \"aita\" / \"aita-test.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T19:17:06.910179Z",
     "start_time": "2020-03-14T19:17:06.563876Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset_df = pd.read_pickle(train_path)\n",
    "test_dataset_df = pd.read_pickle(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add one-hot no embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-13T15:46:23.896076Z",
     "start_time": "2020-03-13T15:46:23.759587Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10223"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract all of the words from our training set and count frequencies\n",
    "word_counts = defaultdict(int)\n",
    "for post in train_dataset_df.selftext.iteritems():\n",
    "    text = post[1].strip().lower()\n",
    "    words = re.findall(r\"[\\w']+|[.,!?;]\", text)\n",
    "    for word in words:\n",
    "        word_counts[word] += 1\n",
    "len(word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-13T15:46:24.972258Z",
     "start_time": "2020-03-13T15:46:24.964380Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2349"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create token mapping\n",
    "word_to_token = dict()\n",
    "token_to_word = dict()\n",
    "word_to_token['<UNK>'] = 0\n",
    "token_to_word[0] = '<UNK>'\n",
    "i = 1\n",
    "for word, count in word_counts.items():\n",
    "    if count < 7:\n",
    "        continue\n",
    "    word_to_token[word] = i\n",
    "    token_to_word[i] = word\n",
    "    i += 1\n",
    "len(word_to_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-13T21:45:23.327480Z",
     "start_time": "2020-03-13T21:45:23.323288Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tokenize and detokenize\n",
    "def tokenize_post(post):\n",
    "    text = post.strip().lower()\n",
    "    words = re.findall(r\"[\\w']+|[.,!?;]\", text)\n",
    "    output = []\n",
    "    for word in words:\n",
    "        output.append(word_to_token.get(word, 0))\n",
    "    return torch.eye(len(word_to_token))[np.array(output)].sum(axis=0)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-13T22:40:39.785900Z",
     "start_time": "2020-03-13T22:40:35.593024Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tokenize reviews in train dataset\n",
    "train_dataset_df['tokenized_selftext'] = train_dataset_df.selftext.apply(tokenize_post)\n",
    "test_dataset_df['tokenized_selftext'] = test_dataset_df.selftext.apply(tokenize_post)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add glove embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T20:00:44.371106Z",
     "start_time": "2020-03-14T20:00:18.539771Z"
    }
   },
   "outputs": [],
   "source": [
    "embeddings_dict = {}\n",
    "with open(\"glove.6B.300d.txt\", 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        token = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        embeddings_dict[token] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T20:04:34.570306Z",
     "start_time": "2020-03-14T20:04:34.566194Z"
    }
   },
   "outputs": [],
   "source": [
    "def selftext_to_glove(text, embedding_size=300):\n",
    "    embeddings = [\n",
    "        embeddings_dict[word.lower().strip()]\n",
    "        for word in text.split()\n",
    "        if word.lower().strip() in embeddings_dict\n",
    "    ]\n",
    "    if embeddings:\n",
    "        glove_embeddings = np.stack(embeddings).mean(axis=0)\n",
    "    else:\n",
    "        glove_embeddings = np.zeros(embedding_size)\n",
    "    return glove_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T20:07:58.095414Z",
     "start_time": "2020-03-14T20:07:50.356260Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset_df['selftext_glove_300'] = train_dataset_df.selftext.apply(selftext_to_glove)\n",
    "test_dataset_df['selftext_glove_300'] = test_dataset_df.selftext.apply(selftext_to_glove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Feed Forward No Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T20:05:14.310936Z",
     "start_time": "2020-03-14T20:05:14.305588Z"
    }
   },
   "outputs": [],
   "source": [
    "class Feedforward(torch.nn.Module):\n",
    "        def __init__(self, input_size, hidden_size, output_size):\n",
    "            super(Feedforward, self).__init__()\n",
    "            self.input_size = input_size\n",
    "            self.hidden_size  = hidden_size\n",
    "            self.output_size = output_size\n",
    "            self.fc1 = torch.nn.Linear(self.input_size, self.hidden_size)\n",
    "            self.relu = torch.nn.ReLU()\n",
    "            self.fc2 = torch.nn.Linear(self.hidden_size, self.output_size)\n",
    "            \n",
    "        def forward(self, x):\n",
    "            hidden = self.fc1(x)\n",
    "            relu = self.relu(hidden)\n",
    "            output = self.fc2(relu)\n",
    "            return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T21:34:53.394309Z",
     "start_time": "2020-03-14T21:34:53.385598Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_features_and_ys(df, features):\n",
    "    feature_df = df[features]\n",
    "    xs = feature_df.apply(\n",
    "        lambda x : np.hstack([np.array(a) for a in x]), axis=1\n",
    "    ).tolist()\n",
    "    label_index = sorted(train_dataset_df.label.unique())\n",
    "    ys = np.array(list(map(label_index.index, df.label.to_list())))\n",
    "    return torch.Tensor(xs), torch.LongTensor(ys)\n",
    "\n",
    "def train_model(model, xs, ys, epochs=10, batch_size=10):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.to(device)\n",
    "    opt = optim.Adam(model.parameters(), lr=0.001)\n",
    "    dataset = torch_data.TensorDataset(xs, ys)\n",
    "    loader = torch_data.DataLoader(dataset, \n",
    "               batch_size=batch_size,\n",
    "               shuffle=True)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        for context, label in loader:\n",
    "            context = context.to(device)\n",
    "            label = label.to(device)\n",
    "            opt.zero_grad()\n",
    "            # Get predictions\n",
    "            outputs = model(context)\n",
    "            # Calculate loss\n",
    "            loss = loss_fn(outputs, label)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            epoch_loss += loss\n",
    "        print(f\"EPOCH {epoch} LOSS = {epoch_loss}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T21:35:04.116043Z",
     "start_time": "2020-03-14T21:34:53.942732Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0 LOSS = 2133.27734375\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-51aea93508d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFeedforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_features_and_ys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'selftext_glove_300'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrained_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-defb71b07d4a>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, xs, ys, epochs, batch_size)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"EPOCH {epoch} LOSS = {epoch_loss}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Feedforward(300, 512, len(train_dataset_df.label.unique()))\n",
    "xs, ys = build_features_and_ys(train_dataset_df, ['selftext_glove_300'])\n",
    "trained_model = train_model(model, xs, ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-13T22:35:36.605234Z",
     "start_time": "2020-03-13T22:35:36.603226Z"
    }
   },
   "source": [
    "## Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T20:06:45.152987Z",
     "start_time": "2020-03-14T20:06:45.149851Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model_accuracy(model, xs, ys):\n",
    "    print(np.mean((model(xs).argmax(axis=1) == ys).numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-14T20:08:04.843909Z",
     "start_time": "2020-03-14T20:08:04.464800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5801302931596091\n"
     ]
    }
   ],
   "source": [
    "test_xs, test_ys = build_features_and_ys(test_dataset_df, ['selftext_glove_300'])\n",
    "get_model_accuracy(trained_model, test_xs, test_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "normal3.8",
   "language": "python",
   "name": "normal3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
